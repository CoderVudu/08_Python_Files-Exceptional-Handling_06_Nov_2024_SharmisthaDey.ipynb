{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOkrg/9fmWZ4yPKXiUaOJJ6",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/CoderVudu/08_Python_Files-Exceptional-Handling_06_Nov_2024_SharmisthaDey.ipynb/blob/main/08_Python_Files_%26_Exceptional_Handling_06_Nov_2024_Sharmistha_Dey.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Q 1.  Discuss the scenarios where multithreading is preferable to multiprocessing and scenarios where multiprocessing is a better choice."
      ],
      "metadata": {
        "id": "SlTF4GyK-ylG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Multithreading is preferable to multiprocessing when tasks are primarily I/O-bound, meaning they spend a lot of time waiting for external operations, such as reading from or writing to disk, network requests, or user input. In these scenarios, multiple threads can efficiently use the CPU's idle time by performing other tasks while waiting for I/O operations to complete. Additionally, multithreading works well in situations where tasks share memory or need to communicate frequently since threads operate within the same memory space, reducing the overhead of inter-process communication (IPC). Examples include web servers managing multiple client requests or GUI applications that need responsive user interfaces.\n",
        "\n",
        "On the other hand, multiprocessing is more suitable for CPU-bound tasks that require significant computational resources, such as large data processing, scientific computations, or machine learning model training. Each process in multiprocessing runs in its own memory space, which can help avoid issues like race conditions and take full advantage of multiple CPU cores. Since processes don't share memory by default, multiprocessing is also a better choice for tasks that require high levels of parallelism without frequent data sharing. Examples include parallel data processing tasks in big data applications or executing simulations that are computationally intensive."
      ],
      "metadata": {
        "id": "JUE-20-J_qIZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Q 2. Describe what a process pool is and how it helps in managing multiple processes efficiently."
      ],
      "metadata": {
        "id": "SbYIsacr_shm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A process pool is a collection of pre-instantiated worker processes that can be reused to execute tasks in parallel. It is designed to manage and streamline the execution of multiple tasks by distributing them among a fixed number of processes within the pool, rather than creating a new process for each task. This approach helps manage resources more efficiently, especially in scenarios where there are a large number of tasks to execute concurrently.\n",
        "\n",
        "In Python, for example, the multiprocessing module provides a `Pool` class, which allows developers to map tasks to worker processes. By using a pool, developers can avoid the high overhead associated with creating and destroying processes repeatedly, as the pool’s processes persist until they are no longer needed.\n",
        "\n",
        "Process pools improve performance and resource utilization by limiting the number of active processes, balancing the workload, and reducing CPU and memory overhead. They are particularly useful for CPU-bound tasks, where parallelism can significantly reduce execution time. Additionally, a process pool can automatically handle task failures and retries, ensuring that the workload is efficiently managed, even if some tasks encounter issues. This makes process pools a powerful tool for optimizing performance in parallel computing."
      ],
      "metadata": {
        "id": "oqIWHA3-_yP_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Q 3.  Explain what multiprocessing is and why it is used in Python programs."
      ],
      "metadata": {
        "id": "CnjZeePe_6Qs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Multiprocessing is a technique that enables a program to run multiple processes simultaneously, allowing it to handle more tasks at once. In Python, multiprocessing is particularly valuable because it helps overcome the Global Interpreter Lock (GIL), a mechanism that prevents multiple threads from executing Python bytecodes at once in a single process. While multithreading allows concurrency, Python’s GIL restricts the performance benefits of multithreading, especially for CPU-bound tasks, as only one thread can execute at a time.\n",
        "\n",
        "By using multiprocessing, Python programs can bypass the GIL and run multiple independent processes with their own memory space. Each process runs on a separate core or CPU, enabling true parallelism. This is especially useful for CPU-intensive tasks, like mathematical computations, data processing, or handling large data sets, where parallel execution significantly speeds up performance.\n",
        "\n",
        "The `multiprocessing` module in Python provides an interface to create and manage processes, passing data between them and synchronizing their execution. It includes features like `Process`, `Pool`, `Queue`, and `Pipe`, which make it easier to implement parallel processing. Overall, multiprocessing is essential in Python for maximizing CPU utilization and improving performance in scenarios where high computational power is required."
      ],
      "metadata": {
        "id": "IYqXXskkACa0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Q 4. Write a Python program using multithreading where one thread adds numbers to a list, and another thread removes numbers from the list. Implement a mechanism to avoid race conditions using threading.Lock."
      ],
      "metadata": {
        "id": "ADZGY5jcAKo3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here is a Python program using threading to implement a producer-consumer scenario with a shared list. The producer thread adds numbers to the list, and the consumer thread removes numbers from it. A threading.Lock is used to ensure thread-safe access to the shared list and prevent race conditions."
      ],
      "metadata": {
        "id": "XmOSIf3TAQv7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import threading\n",
        "import time\n",
        "\n",
        "# Shared list and lock for thread-safe operations\n",
        "shared_list = []\n",
        "lock = threading.Lock()\n",
        "\n",
        "# Producer thread function to add numbers to the list\n",
        "def producer():\n",
        "    for i in range(1, 6):  # Adding 5 numbers as an example\n",
        "        time.sleep(1)  # Simulate time taken to produce\n",
        "        with lock:  # Locking to avoid race condition\n",
        "            shared_list.append(i)\n",
        "            print(f\"Produced: {i}, List: {shared_list}\")\n",
        "\n",
        "# Consumer thread function to remove numbers from the list\n",
        "def consumer():\n",
        "    for _ in range(5):  # Consuming 5 numbers\n",
        "        time.sleep(1.5)  # Simulate time taken to consume\n",
        "        with lock:  # Locking to avoid race condition\n",
        "            if shared_list:\n",
        "                removed_item = shared_list.pop(0)\n",
        "                print(f\"Consumed: {removed_item}, List: {shared_list}\")\n",
        "            else:\n",
        "                print(\"List is empty, waiting...\")\n",
        "\n",
        "# Create and start the threads\n",
        "producer_thread = threading.Thread(target=producer)\n",
        "consumer_thread = threading.Thread(target=consumer)\n",
        "\n",
        "producer_thread.start()\n",
        "consumer_thread.start()\n",
        "\n",
        "# Wait for both threads to complete\n",
        "producer_thread.join()\n",
        "consumer_thread.join()\n",
        "\n",
        "print(\"Processing complete.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "84Oyo4O-Ab1N",
        "outputId": "e8aeb4fd-9c9a-4212-f87e-f3841ff4905c"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Produced: 1, List: [1]\n",
            "Consumed: 1, List: []\n",
            "Produced: 2, List: [2]\n",
            "Produced: 3, List: [2, 3]\n",
            "Consumed: 2, List: [3]\n",
            "Produced: 4, List: [3, 4]\n",
            "Consumed: 3, List: [4]\n",
            "Produced: 5, List: [4, 5]\n",
            "Consumed: 4, List: [5]\n",
            "Consumed: 5, List: []\n",
            "Processing complete.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Q 5.  Describe the methods and tools available in Python for safely sharing data between threads an processes."
      ],
      "metadata": {
        "id": "uzPhorxTAg1l"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In Python, safely sharing data between threads and processes is essential for avoiding race conditions and ensuring data integrity. For **threads** (within the same memory space), the `threading` module provides **Locks**, **RLocks** (re-entrant locks), **Events**, **Conditions**, and **Semaphores** to control access to shared resources. A **Lock** ensures that only one thread accesses critical data at a time. The **Queue** module (FIFO, LIFO, PriorityQueue) is also useful, as it safely passes data between threads by handling locking mechanisms internally.\n",
        "\n",
        "For **multiprocessing** (separate memory spaces), the `multiprocessing` module offers **Queues**, **Pipes**, and **Managers** to facilitate inter-process communication (IPC). A **Queue** provides a FIFO data structure, while **Pipes** enable two-way communication between processes. **Manager objects** create shared objects, like dictionaries or lists, accessible across processes.\n",
        "\n",
        "In shared memory scenarios, `multiprocessing` provides **Value** and **Array** objects, which represent shared data types with synchronization capabilities. Using these tools, developers can share data without explicit locking in certain cases, although it’s often advisable to use **Locks** with shared memory for complex data manipulation.\n",
        "\n",
        "Together, these tools offer effective solutions for managing data sharing safely, whether in a multi-threaded or multi-processed Python environment, enhancing reliability in concurrent applications."
      ],
      "metadata": {
        "id": "ZTLYMBdwAmju"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Q 6.  Discuss why it’s crucial to handle exceptions in concurrent programs and the techniques available for doing so."
      ],
      "metadata": {
        "id": "Rbyx__VLAutM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Handling exceptions in concurrent programs is essential because such programs often operate multiple threads or processes simultaneously, each potentially failing independently. If exceptions are left unhandled, they can cause resource leaks, data corruption, or even program crashes, as well as complicate debugging and maintenance. For instance, one failed thread might lead to inconsistent program states or block the progress of other threads if exceptions are not managed properly.\n",
        "\n",
        "To handle exceptions in concurrent programs, several techniques are available:\n",
        "\n",
        "1. **Try-Catch Blocks in Threads**: Wrapping code in try-catch blocks within each thread allows for local exception handling, preventing a single thread's failure from impacting the entire program.\n",
        "\n",
        "2. **Thread Pool Management**: Using a thread pool helps centralize exception handling, where the framework itself can manage exceptions more robustly.\n",
        "\n",
        "3. **Atomic Operations**: Leveraging atomic operations and transactions ensures that critical sections of code execute without interruptions, reducing the chances of exceptions from race conditions or deadlocks.\n",
        "\n",
        "4. **Executor Services**: In languages like Java, executor services provide managed thread execution and include mechanisms to handle exceptions that arise during task execution.\n",
        "\n",
        "5. **Error Propagation Techniques**: For complex systems, propagating exceptions to a central error handler can enable consistent recovery and logging across threads."
      ],
      "metadata": {
        "id": "e5nTzC-RA2pi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Q 7.  Create a program that uses a thread pool to calculate the factorial of numbers from 1 to 10 concurrently. Use concurrent.futures.ThreadPoolExecutor to manage the threads."
      ],
      "metadata": {
        "id": "blVlGqtQBPn-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here is a Python program that uses concurrent.futures.ThreadPoolExecutor to calculate the factorial of numbers from 1 to 10 concurrently. This implementation sets up a thread pool to manage the threads efficiently, enabling parallel computation of each factorial task."
      ],
      "metadata": {
        "id": "5_0Vocp3BWu8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
        "import math\n",
        "\n",
        "# Function to calculate factorial of a number\n",
        "def calculate_factorial(n):\n",
        "    return math.factorial(n)\n",
        "\n",
        "# Main function to use thread pool for factorial calculations\n",
        "def main():\n",
        "    numbers = range(1, 11)  # Numbers from 1 to 10\n",
        "    results = {}\n",
        "\n",
        "    # Using ThreadPoolExecutor to manage threads\n",
        "    with ThreadPoolExecutor(max_workers=5) as executor:\n",
        "        # Submit tasks to the executor\n",
        "        future_to_number = {executor.submit(calculate_factorial, num): num for num in numbers}\n",
        "\n",
        "        # Collect results as they complete\n",
        "        for future in as_completed(future_to_number):\n",
        "            num = future_to_number[future]\n",
        "            try:\n",
        "                results[num] = future.result()\n",
        "            except Exception as e:\n",
        "                print(f\"Error calculating factorial of {num}: {e}\")\n",
        "\n",
        "    # Print results\n",
        "    for num, factorial in results.items():\n",
        "        print(f\"Factorial of {num} is {factorial}\")\n",
        "\n",
        "# Run the main function\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j2RXG_42Be29",
        "outputId": "da5d6006-b449-414f-e726-41ad8bdc7941"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Factorial of 10 is 3628800\n",
            "Factorial of 9 is 362880\n",
            "Factorial of 8 is 40320\n",
            "Factorial of 3 is 6\n",
            "Factorial of 5 is 120\n",
            "Factorial of 2 is 2\n",
            "Factorial of 1 is 1\n",
            "Factorial of 7 is 5040\n",
            "Factorial of 4 is 24\n",
            "Factorial of 6 is 720\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Q 8. Create a Python program that uses multiprocessing.Pool to compute the square of numbers from 1 to 10 in parallel. Measure the time taken to perform this computation using a pool of different sizes (e.g., 2, 4, 8 processes)."
      ],
      "metadata": {
        "id": "sOYUILAuBidM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To create a Python program that uses multiprocessing.Pool to compute the square of numbers from 1 to 10 in parallel, we can define a function that computes the square of a given number. Then, we create multiple process pools of different sizes (e.g., 2, 4, and 8 processes) to measure the time taken for each pool size to complete the computation."
      ],
      "metadata": {
        "id": "OfvirMz8Bn0q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "from multiprocessing import Pool\n",
        "\n",
        "# Function to compute the square of a number\n",
        "def square(n):\n",
        "    return n * n\n",
        "\n",
        "# Main function to calculate squares in parallel\n",
        "def compute_squares(pool_size):\n",
        "    numbers = list(range(1, 11))  # Numbers from 1 to 10\n",
        "    start_time = time.time()\n",
        "\n",
        "    # Initialize a pool with the given size\n",
        "    with Pool(pool_size) as pool:\n",
        "        results = pool.map(square, numbers)\n",
        "\n",
        "    end_time = time.time()\n",
        "    print(f\"Pool size {pool_size} took {end_time - start_time:.4f} seconds.\")\n",
        "    return results\n",
        "\n",
        "# Test with different pool sizes\n",
        "for pool_size in [2, 4, 8]:\n",
        "    squares = compute_squares(pool_size)\n",
        "    print(f\"Squares with pool size {pool_size}: {squares}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OoDIIAAqBtVc",
        "outputId": "9c2f3705-3680-4955-a333-9c1d39d764c5"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Pool size 2 took 0.0455 seconds.\n",
            "Squares with pool size 2: [1, 4, 9, 16, 25, 36, 49, 64, 81, 100]\n",
            "Pool size 4 took 0.0547 seconds.\n",
            "Squares with pool size 4: [1, 4, 9, 16, 25, 36, 49, 64, 81, 100]\n",
            "Pool size 8 took 0.0940 seconds.\n",
            "Squares with pool size 8: [1, 4, 9, 16, 25, 36, 49, 64, 81, 100]\n"
          ]
        }
      ]
    }
  ]
}